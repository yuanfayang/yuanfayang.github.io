<!DOCTYPE html>
<html class="full-height">
<head>
  <meta charset="utf-8">
  <link rel="stylesheet" href="//cdn.bootcss.com/bulma/0.4.1/css/bulma.min.css">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
  <script src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script>
  
  <title>Netty系列:记一次Netty TCP网关内存异常事件 | Yuan Fayang&#39;s Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="本文记录了一次Netty在物联网中做为TCP长连接网关在压测过成功内存超高，最终导致服务瘫痪的过程。及笔者跟踪解决问题的全过程。">
<meta name="keywords" content="Java,Netty,TCP">
<meta property="og:type" content="article">
<meta property="og:title" content="Netty系列:记一次Netty TCP网关内存异常事件">
<meta property="og:url" content="http://yoursite.com/2017/12/04/记一次Netty+TCP网关内存泄漏事件/index.html">
<meta property="og:site_name" content="Yuan Fayang&#39;s Blog">
<meta property="og:description" content="本文记录了一次Netty在物联网中做为TCP长连接网关在压测过成功内存超高，最终导致服务瘫痪的过程。及笔者跟踪解决问题的全过程。">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://7xpayt.com1.z0.glb.clouddn.com//blog/%E8%AE%B0%E4%B8%80%E6%AC%A1NettyTCP%E7%BD%91%E5%85%B3%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA/dump%E5%BF%AB%E7%85%A7.png">
<meta property="og:image" content="http://7xpayt.com1.z0.glb.clouddn.com//blog/%E8%AE%B0%E4%B8%80%E6%AC%A1NettyTCP%E7%BD%91%E5%85%B3%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA/QQ%E5%9B%BE%E7%89%8720171204090333.png">
<meta property="og:image" content="http://7xpayt.com1.z0.glb.clouddn.com//blog/%E8%AE%B0%E4%B8%80%E6%AC%A1NettyTCP%E7%BD%91%E5%85%B3%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA/%E6%9C%8D%E5%8A%A1%E7%9B%91%E8%A7%86.png">
<meta property="og:image" content="http://7xpayt.com1.z0.glb.clouddn.com//blog/%E8%AE%B0%E4%B8%80%E6%AC%A1NettyTCP%E7%BD%91%E5%85%B3%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA/gcutil.png">
<meta property="og:image" content="http://7xpayt.com1.z0.glb.clouddn.com//blog/%E8%AE%B0%E4%B8%80%E6%AC%A1NettyTCP%E7%BD%91%E5%85%B3%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA/%E6%97%A5%E5%BF%97%E6%89%93%E5%8D%B0.png">
<meta property="og:image" content="http://7xpayt.com1.z0.glb.clouddn.com//blog/%E8%AE%B0%E4%B8%80%E6%AC%A1NettyTCP%E7%BD%91%E5%85%B3%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA/%E5%8D%95%E4%B8%80%E5%AE%A2%E6%88%B7%E7%AB%AFtcpdump.png">
<meta property="og:image" content="http://7xpayt.com1.z0.glb.clouddn.com//blog/%E8%AE%B0%E4%B8%80%E6%AC%A1NettyTCP%E7%BD%91%E5%85%B3%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA/QQ%E6%88%AA%E5%9B%BE20171204090457.png">
<meta property="og:updated_time" content="2017-12-08T09:25:19.273Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Netty系列:记一次Netty TCP网关内存异常事件">
<meta name="twitter:description" content="本文记录了一次Netty在物联网中做为TCP长连接网关在压测过成功内存超高，最终导致服务瘫痪的过程。及笔者跟踪解决问题的全过程。">
<meta name="twitter:image" content="http://7xpayt.com1.z0.glb.clouddn.com//blog/%E8%AE%B0%E4%B8%80%E6%AC%A1NettyTCP%E7%BD%91%E5%85%B3%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA/dump%E5%BF%AB%E7%85%A7.png">
  
    <link rel="alternate" href="/atom.xml" title="Yuan Fayang&#39;s Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/common.css">
<link rel="stylesheet" href="/css/nav.css">
<link rel="stylesheet" href="/css/layout.css">
  

</head>

<body>
  <header id="navbar" class="overflow-hidden">
  <div class="container">
    <nav class="nav">
         <div class="nav-left">
            <a href="/" class="nav-item" style="font-size: 20px;">
              <span class="logo">Nemo Yuan</span>'s Blog
            </a>
         </div>
        <div class="nav-center is-hidden position-relative" id="search_container">
            <div class="nav-item full-width full-height">
                <i class="fa fa-search has-padding" aria-hidden="true"></i>
                <input type="text" id="search_input" class="search-input full-height full-width" placeholder="Search post" autofocus>
                <i id="close_search" class="fa fa-times" aria-hidden="true"></i>
            </div>
            <div id="search_result"></div>
        </div>
        <div class="nav-right nav-menu">
            <a class="nav-item" id="search">
                <i class="fa fa-search" aria-hidden="true"></i>
            </a>
            
            <a class="nav-item" href="/">
                Home
            </a>
            
            <a class="nav-item" href="/about">
                About
            </a>
            
        </div>
        <span class="nav-toggle" id="navMenuDropdown">
            <span></span>
            <span></span>
            <span></span>
        </span>
        <div class="navbar-menu position-absolute full-width content-box is-hidden-desktop is-flex flex-column center" style="top: 100%;">
            
            <a class="nav-item flex-1" href="/">
                Home
            </a>
            
            <a class="nav-item flex-1" href="/about">
                About
            </a>
            
        </div>
    </nav>
  </div>
</header>

  <div id="main-wrap" class="position-relative" style="margin-top: 55px;">
      <div class="main-inner-content">
          <!--博文页面-->

<style>
    .header-box {
        height: 370px;
        filter: blur(10px);
        background-size: cover;
        background-color: lightsteelblue;
    }

    .post-box {
        padding: 15px;
        padding-top: 60px;
        min-height: 80vh;
        margin-top: -200px;
        border-radius: 4px;
        background-color: rgba(255,255,255,.8);
    }

    .post-avatar {
        height: 30px;
        width: 30px;
        border-radius: 50%;
    }

    .flow-chart {
        text-align: center;
    }

    img[alt="post-cover"] {
        display: none;
    }
</style>
<header>
    <div id="header_box" class="header-box"></div>
</header>
<section>
    <div class="container post-box">
        <div class="content post-title is-flex center flex-column" style="margin-bottom: 70px; overflow: auto;">
            <h1 class="has-text-centered" style="padding-bottom: 10px; border-bottom: 3px solid #fff">
                <strong>Netty系列:记一次Netty TCP网关内存异常事件</strong>
            </h1>
            
            <div class="is-flex align-center">
                <img class="post-avatar" src="http://7xpayt.com1.z0.glb.clouddn.com/bug%E6%9D%A5%E4%BA%86.jpg">
                <span style="padding:0 10px;"> <span class="sub-title">By</span> Nemo Yuan</span>
                <span class="post-date sub-title">at: 2017-12-04</span>
            </div>
            
                <div>
                    
                         <a class="tag is-post-tag" href="/tags/Java/">Java</a>
                    
                         <a class="tag is-post-tag" href="/tags/Netty/">Netty</a>
                    
                         <a class="tag is-post-tag" href="/tags/TCP/">TCP</a>
                    
                </div>
            
        </div>
        <div class="content" style="overflow: auto">
            <h3 id="1-问题出现"><a href="#1-问题出现" class="headerlink" title="1.问题出现"></a>1.问题出现</h3><p>笔者在一个设备控制类型项目中用到了Netty做TCP长连接网关，至于Netty的优势和选择的Netty的理由笔者就不在此赘述。本文主要目的是描述在这次项目过程中遇到的网关服务器内存超高现象，以及笔者整个排查和处理过程。<br>事件的经过大体是这样的。笔者基于Netty实现了私有的设备控制协议进行设备控制。待到代码基本稳定之后，笔者联合测试人员准备对网关进行一次性能测试。客户端起5000线程，采用10s心跳进行设备在线模拟。测试刚开始一切正常，等到运行3小时左右，网关内存占用开始逐步走高，运行6小时左右，内存占用达到90%以上甚至100%。而此时，<code>JVM</code>开始频繁进行<code>Full GC</code>,但是每次<code>Full GC</code>均不能回收老生带堆内存空间,<code>Full GC</code>的循环执行，导致CPU 100%。最终，服务端杀掉了所有连接。</p>
<h3 id="2-问题分析"><a href="#2-问题分析" class="headerlink" title="2.问题分析"></a>2.问题分析</h3><p>笔者及同事在测试过程中，一直使用<code>jvisualvm</code>和<code>jmeter</code>监视运行情况，间隔使用<code>top</code>，<code>jstat</code>等命令进行监视。知道问题出现，笔者使用<code>jmap</code>命令（<code># jmap -dump:live,format=b,file=heap.dmp 90453</code>）生成堆内存快照文件，拖到本地使用<code>MAT</code>进行内存分析。<br><img src="http://7xpayt.com1.z0.glb.clouddn.com//blog/%E8%AE%B0%E4%B8%80%E6%AC%A1NettyTCP%E7%BD%91%E5%85%B3%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA/dump%E5%BF%AB%E7%85%A7.png" alt="内存dump">  </p>
<h4 id="2-1dump结合源码分析"><a href="#2-1dump结合源码分析" class="headerlink" title="2.1dump结合源码分析"></a>2.1dump结合源码分析</h4><p>上图红线框出的”三座大山”是本次事件的元凶。<code>io.netty.buffer.PooledUnsafeDirectByteBuf</code>来自于Netty缓冲区分配，由Netty直接管理，回收使用的是Netty仿照JVM实现的标记回收算法。Netty 4 默认采用的就是内存池。<code>io.netty.util.Recycler</code> 的源码注释中是这么写的:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * Light-weight object pool based on a thread-local stack.</span><br><span class="line"> *</span><br><span class="line"> * @param &lt;T&gt; the type of the pooled object</span><br><span class="line"> */</span><br></pre></td></tr></table></figure></p>
<p>可见<code>io.netty.util.Recycler</code> 其实是Netty的资源池。通过阅读Netty代码，笔者发现，<code>io.netty.util.Recycler$DefaultHandle</code>飙高和 ByteBuf的分配是有关联关系的。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">final class PooledUnsafeDirectByteBuf extends PooledByteBuf&lt;ByteBuffer&gt; &#123;</span><br><span class="line">    private static final Recycler&lt;PooledUnsafeDirectByteBuf&gt; RECYCLER = new Recycler&lt;PooledUnsafeDirectByteBuf&gt;() &#123;</span><br><span class="line">        @Override</span><br><span class="line">        protected PooledUnsafeDirectByteBuf newObject(Handle&lt;PooledUnsafeDirectByteBuf&gt; handle) &#123;</span><br><span class="line">            return new PooledUnsafeDirectByteBuf(handle, 0);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line"></span><br><span class="line">    static PooledUnsafeDirectByteBuf newInstance(int maxCapacity) &#123;</span><br><span class="line">        PooledUnsafeDirectByteBuf buf = RECYCLER.get();</span><br><span class="line">        buf.reuse(maxCapacity);</span><br><span class="line">        return buf;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>以上是<code>PooledUnsafeDirectByteBuf</code>的部分源码，我们可以看到用到了<code>Recycler</code>,也用到了<code>get()</code>方法。进入方法内部：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">@SuppressWarnings(&quot;unchecked&quot;)</span><br><span class="line">public final T get() &#123;</span><br><span class="line">    if (maxCapacityPerThread == 0) &#123;</span><br><span class="line">        return newObject((Handle&lt;T&gt;) NOOP_HANDLE);</span><br><span class="line">    &#125;</span><br><span class="line">    Stack&lt;T&gt; stack = threadLocal.get();</span><br><span class="line">    DefaultHandle&lt;T&gt; handle = stack.pop();</span><br><span class="line">    if (handle == null) &#123;</span><br><span class="line">        handle = stack.newHandle();</span><br><span class="line">        handle.value = newObject(handle);</span><br><span class="line">    &#125;</span><br><span class="line">    return (T) handle.value;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p><code>get()</code>的逻辑是，资源池中handle紧张的情况下，就创建新的handle。<code>stack.newHandle();</code>内部:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"> DefaultHandle&lt;T&gt; newHandle() &#123;</span><br><span class="line">    return new DefaultHandle&lt;T&gt;(this);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>这里就新建了<code>DefaultHandle</code>。<br><code>io.netty.channel.ChannelOutboundBuffer</code>源码注释为出站缓存数据结构。自然是跟调用<code>writeAndFlush()</code>方法有关系。debug模式跟踪代码发现，在<code>AbstractChannel</code>中执行了<code>ChannelOutboundBuffer</code>的分配:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"> @Override</span><br><span class="line">public final void write(Object msg, ChannelPromise promise) &#123;</span><br><span class="line">    assertEventLoop();</span><br><span class="line"></span><br><span class="line">    ChannelOutboundBuffer outboundBuffer = this.outboundBuffer;</span><br><span class="line">    if (outboundBuffer == null) &#123;</span><br><span class="line">        // If the outboundBuffer is null we know the channel was closed and so</span><br><span class="line">        // need to fail the future right away. If it is not null the handling of the rest</span><br><span class="line">        // will be done in flush0()</span><br><span class="line">        // See https://github.com/netty/netty/issues/2362</span><br><span class="line">        safeSetFailure(promise, WRITE_CLOSED_CHANNEL_EXCEPTION);</span><br><span class="line">        // release message now to prevent resource-leak</span><br><span class="line">        ReferenceCountUtil.release(msg);</span><br><span class="line">        return;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    int size;</span><br><span class="line">    try &#123;</span><br><span class="line">        msg = filterOutboundMessage(msg);</span><br><span class="line">        size = pipeline.estimatorHandle().size(msg);</span><br><span class="line">        if (size &lt; 0) &#123;</span><br><span class="line">            size = 0;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; catch (Throwable t) &#123;</span><br><span class="line">        safeSetFailure(promise, t);</span><br><span class="line">        ReferenceCountUtil.release(msg);</span><br><span class="line">        return;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    outboundBuffer.addMessage(msg, size, promise);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>顺便额外说一句，笔者走读代码的过程中，随处都能看到Netty执行<code>release()</code>,所以笔者有理由相信Netty的回收机制是健全的。通过上面代码发现，<code>AbstractChannel</code>并没有执行IO操作，而是执行了<code>addMessage()</code>,继续跟踪<code>addMessage()</code>:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line">* Add given message to this &#123;@link ChannelOutboundBuffer&#125;. The given &#123;@link ChannelPromise&#125; will be notified once</span><br><span class="line">* the message was written.</span><br><span class="line">*/</span><br><span class="line">public void addMessage(Object msg, int size, ChannelPromise promise) &#123;</span><br><span class="line">    Entry entry = Entry.newInstance(msg, size, total(msg), promise);</span><br><span class="line">    if (tailEntry == null) &#123;</span><br><span class="line">        flushedEntry = null;</span><br><span class="line">        tailEntry = entry;</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        Entry tail = tailEntry;</span><br><span class="line">        tail.next = entry;</span><br><span class="line">        tailEntry = entry;</span><br><span class="line">    &#125;</span><br><span class="line">    if (unflushedEntry == null) &#123;</span><br><span class="line">        unflushedEntry = entry;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // increment pending bytes after adding message to the unflushed arrays.</span><br><span class="line">    // See https://github.com/netty/netty/issues/1619</span><br><span class="line">    incrementPendingOutboundBytes(size, false);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>这里出现了<code>Entry</code>，<code>io.netty.channel.ChannelOutboundBuffer$Entry</code>露出了庐山真面目。继续读代码:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">private void incrementPendingOutboundBytes(long size, boolean invokeLater) &#123;</span><br><span class="line">    if (size == 0) &#123;</span><br><span class="line">        return;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    long newWriteBufferSize = TOTAL_PENDING_SIZE_UPDATER.addAndGet(this, size);</span><br><span class="line">    if (newWriteBufferSize &gt; channel.config().getWriteBufferHighWaterMark()) &#123;</span><br><span class="line">        setUnwritable(invokeLater);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>可见，在addMessage之后OutboundBuffer会动态扩展，但是当到达了设置的水位之后,channel会被置为，不可写状态。  </p>
<p>Netty的write并没有实际的IO，正的IO是在flush中，下面跟踪代码。<code>AbstractChannelHandlerContext</code>中flush方法<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">@Override</span><br><span class="line">public ChannelHandlerContext flush() &#123;</span><br><span class="line">    final AbstractChannelHandlerContext next = findContextOutbound();</span><br><span class="line">    EventExecutor executor = next.executor();</span><br><span class="line">    if (executor.inEventLoop()) &#123;</span><br><span class="line">        next.invokeFlush();</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        Runnable task = next.invokeFlushTask;</span><br><span class="line">        if (task == null) &#123;</span><br><span class="line">            next.invokeFlushTask = task = new Runnable() &#123;</span><br><span class="line">                @Override</span><br><span class="line">                public void run() &#123;</span><br><span class="line">                    next.invokeFlush();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;;</span><br><span class="line">        &#125;</span><br><span class="line">        safeExecute(executor, task, channel().voidPromise(), null);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    return this;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>这里并没有什么实质性的flush逻辑，只是判定是否是当前线程，决定是否立即执行flush。如果不是，则生成一个线程任务。值得注意的是，Netty在做write操作的时候，都要求在当前线程中完成，否则资源无法回收。<br>真正的flush执行是在<code>AbstractChannel</code>中：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line">@Override</span><br><span class="line">public final void flush() &#123;</span><br><span class="line">    assertEventLoop();</span><br><span class="line"></span><br><span class="line">    ChannelOutboundBuffer outboundBuffer = this.outboundBuffer;</span><br><span class="line">    if (outboundBuffer == null) &#123;</span><br><span class="line">        return;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    outboundBuffer.addFlush();</span><br><span class="line">    flush0();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">@SuppressWarnings(&quot;deprecation&quot;)</span><br><span class="line">protected void flush0() &#123;</span><br><span class="line">    if (inFlush0) &#123;</span><br><span class="line">        // Avoid re-entrance</span><br><span class="line">        return;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    final ChannelOutboundBuffer outboundBuffer = this.outboundBuffer;</span><br><span class="line">    if (outboundBuffer == null || outboundBuffer.isEmpty()) &#123;</span><br><span class="line">        return;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    inFlush0 = true;</span><br><span class="line"></span><br><span class="line">    // Mark all pending write requests as failure if the channel is inactive.</span><br><span class="line">    if (!isActive()) &#123;</span><br><span class="line">        try &#123;</span><br><span class="line">            if (isOpen()) &#123;</span><br><span class="line">                outboundBuffer.failFlushed(FLUSH0_NOT_YET_CONNECTED_EXCEPTION, true);</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                // Do not trigger channelWritabilityChanged because the channel is closed already.</span><br><span class="line">                outboundBuffer.failFlushed(FLUSH0_CLOSED_CHANNEL_EXCEPTION, false);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; finally &#123;</span><br><span class="line">            inFlush0 = false;</span><br><span class="line">        &#125;</span><br><span class="line">        return;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    try &#123;</span><br><span class="line">        doWrite(outboundBuffer);</span><br><span class="line">    &#125; catch (Throwable t) &#123;</span><br><span class="line">        if (t instanceof IOException &amp;&amp; config().isAutoClose()) &#123;</span><br><span class="line">            /**</span><br><span class="line">                * Just call &#123;@link #close(ChannelPromise, Throwable, boolean)&#125; here which will take care of</span><br><span class="line">                * failing all flushed messages and also ensure the actual close of the underlying transport</span><br><span class="line">                * will happen before the promises are notified.</span><br><span class="line">                *</span><br><span class="line">                * This is needed as otherwise &#123;@link #isActive()&#125; , &#123;@link #isOpen()&#125; and &#123;@link #isWritable()&#125;</span><br><span class="line">                * may still return &#123;@code true&#125; even if the channel should be closed as result of the exception.</span><br><span class="line">                */</span><br><span class="line">            close(voidPromise(), t, FLUSH0_CLOSED_CHANNEL_EXCEPTION, false);</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            outboundBuffer.failFlushed(t, true);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; finally &#123;</span><br><span class="line">        inFlush0 = false;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p><code>flush0()</code>中调用了<code>doWrite()</code>进行IO流输出，同时，监测了各种异常情况，并执行事件回调。<br>至此，Netty writeAndFlush的源码已分析完了。结合dump的情况来看，笔者有点怀疑是<strong>TCP出口积压导致ChannelOutboundBuffer堆积耗尽了内存</strong>，从源码上来看，write一直在进行资源的消耗，而必须依赖flush的成功执行才能正常回收资源。而且，Netty在执行write的时候，并没有对channel的写入状态，或者缓冲区的状态进行检测。这样一来，在对端处理不及时的情况下，是有可能造成写出缓冲区积压的。于是，笔者着手重构这一部分代码，在自己的业务代码中加入相应的判断逻辑。</p>
<h3 id="3-修改并回归"><a href="#3-修改并回归" class="headerlink" title="3.修改并回归"></a>3.修改并回归</h3><p>笔者简单的封装了<code>writeAndFlush()</code>,包裹了channel写入状态的检测逻辑，并且添加了消息写入结果的listener，只是在异常状态下，笔者并没有做过多的处理，只是简单的输出日志。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line">* 静态方法向channel中写入消息</span><br><span class="line">*</span><br><span class="line">* @param ctx</span><br><span class="line">*/</span><br><span class="line">private static void writeAndFlush(ChannelHandlerContext ctx, byte[] msg) &#123;</span><br><span class="line">        ByteBuf byteBuf = Unpooled.copiedBuffer(msg);</span><br><span class="line">        Channel channel = ctx.channel();</span><br><span class="line"></span><br><span class="line">        //检测是否可写入</span><br><span class="line">        if (channel.isWritable()) &#123;</span><br><span class="line">            ChannelFuture channelFuture = ctx.writeAndFlush(byteBuf);</span><br><span class="line">            if (channelFuture != null) &#123;</span><br><span class="line">                channelFuture.addListener(new ChannelFutureListener() &#123;</span><br><span class="line">                    @Override</span><br><span class="line">                    public void operationComplete(ChannelFuture channelFuture) throws Exception &#123;</span><br><span class="line">                        Channel ch = channelFuture.channel();</span><br><span class="line">                        String eqSn = null;</span><br><span class="line">                        if (ch != null) &#123;</span><br><span class="line">                            Attribute&lt;String&gt; attr = ch.attr(AttributeMapConstant.CHANNEL_SN_KEY);</span><br><span class="line">                            eqSn = attr.get();</span><br><span class="line">                        &#125;</span><br><span class="line">                        if (channelFuture != null) &#123;</span><br><span class="line">                            if (channelFuture.isSuccess()) &#123;</span><br><span class="line">                                logger.debug(&quot;send message success!&quot;);</span><br><span class="line">                            &#125; else &#123;</span><br><span class="line">                                logger.error(&quot;send message error! sn:&#123;&#125; , channel:&#123;&#125;&quot;, eqSn, ch.hashCode());</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            Attribute&lt;String&gt; attr = channel.attr(AttributeMapConstant.CHANNEL_SN_KEY);</span><br><span class="line">            String sn = attr.get();</span><br><span class="line">            logger.warn(&quot;write queue is busy! sn:&#123;&#125; , channel:&#123;&#125;&quot;, sn, channel.hashCode());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></p>
<p>代码完成修改，接下来是部署测试环境验证效果。为了尽可能多的暴露问题，笔者在启动命令中处理JVM的参数、JMX监控之外，还添加了GC日志打印，并将Netty内存泄漏等级配置为advanced（<code>-Dio.netty.leakDetectionLevel=advanced</code>）<br>启动命令：<br><code>nohup java -Xmx7168m -Xms5120m -Xmn2g -XX:PermSize=80m -XX:MaxPermSize=80m -XX:+PrintGC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCApplicationStoppedTime -Xloggc:/home/app/nettyLogs/gc.log -Dio.netty.leakDetectionLevel=advanced -Djava.rmi.server.hostname=172.19.2.168 -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.port=22222 -jar speaker-gateway-0.0.1-SNAPSHOT-jar-with-dependencies.jar &amp;</code><br>网关在测试环境启动后，照样采用5000模拟终端，10s心跳间隔压测。<br><img src="http://7xpayt.com1.z0.glb.clouddn.com//blog/%E8%AE%B0%E4%B8%80%E6%AC%A1NettyTCP%E7%BD%91%E5%85%B3%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA/QQ%E5%9B%BE%E7%89%8720171204090333.png" alt="终端数">  </p>
<p>再次测试之后，连接数一直没有掉。这对于笔者来说，算是成功了一方面。  </p>
<p><img src="http://7xpayt.com1.z0.glb.clouddn.com//blog/%E8%AE%B0%E4%B8%80%E6%AC%A1NettyTCP%E7%BD%91%E5%85%B3%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA/%E6%9C%8D%E5%8A%A1%E7%9B%91%E8%A7%86.png" alt="jvisualvm服务监视">  </p>
<p><img src="http://7xpayt.com1.z0.glb.clouddn.com//blog/%E8%AE%B0%E4%B8%80%E6%AC%A1NettyTCP%E7%BD%91%E5%85%B3%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA/gcutil.png" alt="jstat">  </p>
<p>虽然从监控的图形上来看，表现有点怪异，单总体来说还是正常的。jstat命令现实，没有频繁执行full gc的现象了，这也是连接数能保持的原因。  </p>
<p>再查看日志，笔者发现了问题：<br><img src="http://7xpayt.com1.z0.glb.clouddn.com//blog/%E8%AE%B0%E4%B8%80%E6%AC%A1NettyTCP%E7%BD%91%E5%85%B3%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA/%E6%97%A5%E5%BF%97%E6%89%93%E5%8D%B0.png" alt="写出队列满日志"><br>日志的情况已经说明了刚才笔者修改的代码执行了else，即channel在这个时候已经是处于不可写的状态了。而此时channel不可写，极有可能就是缓冲区占满，到达高水位（<code>HIGH_WATER_MARK</code>）导致的。再联想到，测试人员给笔者提过，为了节省压力机的资源，模拟终端并未读取网关回发的TCP报文。于是，笔者就进一步猜想，<strong>模拟终端未读取TCP报文，长时间导致接收缓冲区占满，导致无法再正常收取TCP报文。也因此，网关无法正常向模拟终端发送报文，导致了写出缓冲区积压引起内存异常。</strong>要真是这样，那应该一个模拟终端线程连接的时候，运行到相同的时间点，虽然内存挤占不会明显的如5000线程的情况下那么明显，但是TCP的表现应该是差不多的。于是笔者决定，启用一个模拟终端进行测试，并且结合<code>tcpdump</code>命令和wireshark工具查看TCP报文收发情况。结果，和笔者预期的一样，一开始心跳请求和应答都正常，但是到达3h的分水岭的时候，网关就只能接收心跳请求，并不能发送心跳应答。日志跟之前5000模拟终端情况下一致，显示写出缓冲区占满。  </p>
<p><img src="http://7xpayt.com1.z0.glb.clouddn.com//blog/%E8%AE%B0%E4%B8%80%E6%AC%A1NettyTCP%E7%BD%91%E5%85%B3%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA/%E5%8D%95%E4%B8%80%E5%AE%A2%E6%88%B7%E7%AB%AFtcpdump.png" alt="tcpdump"></p>
<h3 id="4-问题解决"><a href="#4-问题解决" class="headerlink" title="4.问题解决"></a>4.问题解决</h3><p>至此，笔者虽然不敢认定发现了全部的症结所在，但是至少能确定发现了其中的一部分问题。于是协调测试人员修改模拟终端，接受网关的心跳报文。最终结果是，不管是在1个终端，还是多个模拟终端压测的情况下，都不会出现channel不可写入，写出缓冲区积压的情况，TCP收发都很正常。但是让笔者和测试人员无解的是，服务器内存还是会以比较缓慢的速度升高。总的来说，尖锐的引起服务瘫痪的问题，已经处理了。缓慢上升会不会导致资源耗尽？会不会引起服务瘫痪？还需要更长时间，更加充分的测试。笔者虽然不爽，但也只有将它列为下一个目标，发誓全面抗战到底！  </p>
<p><img src="http://7xpayt.com1.z0.glb.clouddn.com//blog/%E8%AE%B0%E4%B8%80%E6%AC%A1NettyTCP%E7%BD%91%E5%85%B3%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA/QQ%E6%88%AA%E5%9B%BE20171204090457.png" alt="服务器内存升高"></p>
<h3 id="5-总结"><a href="#5-总结" class="headerlink" title="5.总结"></a>5.总结</h3><p>虽然本次压测暴露出来的问题，很大程度上是因为模拟终端不处理TCP收包。但是作为网关服务端，就稳定和健壮性方面考虑，还是应该在执行writeAndFlush之前，对channel的写入状态，缓冲区的状态进行检测，并添加相应的容错机制。虽然正式应用场景下，不会有终端不收包的情况，但是仍然存在着网络不畅，终端处理不过来等情况可能引起缓存积压。<br>Netty的<code>writeAndFlush()</code>，会默认创建一个DefaultChannelPromise（如下代码所示），如果不需要ChannelFuture,可是调用时传入一个VoidChannelPromise，具体操作可以调用channel的<code>voidPromise()</code>api(示例：<code>ctx.writeAndFlush(byteBuf,channel.voidPromise()</code>)。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">@Override</span><br><span class="line">public ChannelFuture writeAndFlush(Object msg) &#123;</span><br><span class="line">    return writeAndFlush(msg, newPromise());</span><br><span class="line">&#125;</span><br><span class="line"> @Override</span><br><span class="line">public ChannelPromise newPromise() &#123;</span><br><span class="line">    return new DefaultChannelPromise(channel(), executor());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>

        </div>
        <div class="post-reply">
            
                <!-- 来必力City版安装代码 -->
                <div id="lv-container" data-id="city" data-uid="MTAyMC8yOTE4Ni81NzUz">
                    <script type="text/javascript">
                        (function(d, s) {
                            var j, e = d.getElementsByTagName(s)[0];

                            if (typeof LivereTower === 'function') { return; }

                            j = d.createElement(s);
                            j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
                            j.async = true;

                            e.parentNode.insertBefore(j, e);
                        })(document, 'script');
                    </script>
                    <noscript> 为正常使用来必力评论功能请激活JavaScript</noscript>
                </div>
                <!-- City版安装代码已完成 -->
            
            
        </div>
    </div>
</section>
<script>
    // 获取第一张图, 用以当封面背景图
    var img = document.querySelectorAll('img')[1]

    if (img) {
        var header_box = document.querySelector('#header_box')
        header_box.style.backgroundImage = 'url('+ img.src +')'
    }
</script>
      </div>
  </div>
  <style>
  #footer {
    min-height: 10vh;
    background: black;
    color: #fff;
  }

  #footer a {
    color: #e1e1e1;
  }
</style>
<footer id="footer" class="has-text-centered is-flex center">
  <div class="container has-padding">
    <div>
      <div>
        <!--请您保留作者署名, 主题制作来之不易-->
        Theme by <a href="http://haojen.github.io/">Haojen Ma</a>
        <br>
        Copyright © 袁发洋 2017
        <br>
        Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      </div>
    </div>
  </div>
</footer>

<script src="/js/search_core.js"></script>
<script src="/js/script.js"></script>

</body>
</html>